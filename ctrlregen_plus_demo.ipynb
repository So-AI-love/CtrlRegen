{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import ControlNetModel, UniPCMultistepScheduler, AutoencoderKL, StableDiffusionControlNetImg2ImgPipeline\n",
    "from controlnet_aux import CannyDetector\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms \n",
    "from transformers import AutoModel, AutoImageProcessor\n",
    "from utils import color_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "transform_size_to_512 = transforms.Compose([\n",
    "        transforms.Resize(512, interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "        transforms.CenterCrop(512),\n",
    "        ])\n",
    "\n",
    "DIFFUSION_MODEL = 'SG161222/Realistic_Vision_V4.0_noVAE'\n",
    "SPATIAL_CONTROL_PATH = 'path/to/spatial_control_checkpoint'\n",
    "SEMANTIC_CONTROL_PATH = 'path/to/semantic_control'\n",
    "SEMANTIC_CONTROL_NAME = 'checkpoint_name'\n",
    "IMAGE_ENCODER = 'facebook/dinov2-giant'\n",
    "VAE = 'stabilityai/sd-vae-ft-mse'\n",
    "\n",
    "spatialnet = [ControlNetModel.from_pretrained(SPATIAL_CONTROL_PATH, torch_dtype=torch.float16)]\n",
    "pipe = StableDiffusionControlNetImg2ImgPipeline.from_pretrained(DIFFUSION_MODEL, \\\n",
    "                                                         controlnet=spatialnet, \\\n",
    "                                                         torch_dtype=torch.float16,\n",
    "                                                         safety_checker = None,\n",
    "                                                         requires_safety_checker = False\n",
    "                                                         )\n",
    "pipe.load_ip_adapter(SEMANTIC_CONTROL_PATH, subfolder='models', weight_name=SEMANTIC_CONTROL_NAME)\n",
    "pipe.image_encoder = AutoModel.from_pretrained(IMAGE_ENCODER).to(device, dtype=torch.float16)\n",
    "pipe.feature_extractor = AutoImageProcessor.from_pretrained(IMAGE_ENCODER)\n",
    "pipe.vae = AutoencoderKL.from_pretrained(VAE).to(dtype=torch.float16)\n",
    "pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "pipe.set_ip_adapter_scale(1.0)\n",
    "pipe.set_progress_bar_config(disable=True)\n",
    "pipe.to(device)\n",
    "\n",
    "processor = CannyDetector()\n",
    "\n",
    "def ctrl_regen_plus(input_img, step):\n",
    "    generator = torch.manual_seed(0)\n",
    "    input_img = transform_size_to_512(input_img)\n",
    "    processed_img = processor(input_img, low_threshold=100, high_threshold=150)\n",
    "    prompt = 'best quality, high quality'\n",
    "    negative_prompt = 'monochrome, lowres, bad anatomy, worst quality, low quality'\n",
    "    output_img = pipe(prompt,\n",
    "                      negative_prompt=negative_prompt,\n",
    "                      image = [input_img],\n",
    "                      control_image = [processed_img], # spatial condition\n",
    "                      ip_adapter_image = [input_img],   # semantic condition\n",
    "                      strength = step,\n",
    "                      generator = generator,\n",
    "                      num_inference_steps=50,\n",
    "                      controlnet_conditioning_scale = 1.0,\n",
    "                      guidance_scale = 2.0,\n",
    "                      control_guidance_start = 0,\n",
    "                      control_guidance_end = 1,\n",
    "                      ).images[0]\n",
    "    output_img = color_match(input_img, output_img)\n",
    "    return output_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = 'path/to/your/image'\n",
    "input_img = Image.open(IMAGE_PATH)\n",
    "output_img = ctrl_regen_plus(input_img=input_img, step=0.5)   # step could be between 0 and 1\n",
    "output_img"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
